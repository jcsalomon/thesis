% !TEX TS-program = xelatex 
% !TEX encoding = UTF-8
\documentclass{article}

\usepackage{jcs-thesis-fonts}
\usepackage{jcs-thesis-punct}
\usepackage{jcs-thesis-dates}
\usepackage{jcs-thesis-math}
\usepackage{jcs-thesis-theorem}
\usepackage{jcs-thesis-graphics}
\usepackage{jcs-thesis-bibidxref}

\newcommand*{\presection}{\medskip\noindent}

\urlstyle{same}
\def\UrlLeft#1\UrlRight{‹#1›}

\begin{document}
\title{Control Systems for the\\%
%	Northrop Grumman\\%
	Lunar Lander X-Prize Challenge\\%
	Interim Report \No 2:\\%
	Dynamic Programming}
\author{Joel C. Salomon}
\date{\today\\\currenttime}
\special{pdf: docinfo <<
	/Title		(Thesis Report 2: Dynamic Programming)
\ifxetex /Creator	(XɘLᴬTeX with hyperref package)\else\fi
	/Author	(Joel C. Salomon)
	/CreationDate	(D:20100514120000)
	/ModDate	(D:\pdfdate)
	/Subject	(Engineering)
	/Keywords	(control systems;optimal control;dynamic programming;rocket landing)
	>>}
%\cleardoublepage
\maketitle

\section*{Overview}
To recap from Interim Report \No~1,
the optimal control problem boils down to
finding a suitable control trajectory $\vecu$
which will cause the system,
itself describable by 
\begin{equation}
	\label{rpt:forml:eq:stateeq:vect}
	\tag{\textsc{r}1:1${}′$}
	\dot{\vecx}(t) =
		\func{\veca}{\vecx(t), \vecu(t), t}
\end{equation}
which will minimize the performance measure
\begin{equation}
	\label{rpt:forml:eq:measure}
	\tag{\textsc{r}1:2}
	J = \func{h}{\vecx(t_\fl),t_\fl} +
		\intt{\func{g}{\vecx(t), \vecu(t), t} \dd t}.
\end{equation}
(Equation numbers beginning with \textsc{r}$x$
refer to previous reports, so that
\cref{rpt:forml:eq:stateeq:vect,rpt:forml:eq:measure}
refer to equations (1${}′$) and (2)
\citetitle[from][]{salomon:report1}.)

This report will discuss the use of
\emph{dynamic programming} in optimization.
As before, the notation used in this report
largely follows Kirk’s \citetitle{kirk:optintro}.

\tableofcontents

\section{Admissibility}
In the previous report (§1.2) I simply mentioned that
“[t]here will often be constraints on the states or the control inputs”
and glossed over the issue of admissibility,
so a short digression in that direction is in order.

\begin{defn}
	Almost all real-life systems will have constraints,
	whether physical or regulatory.
	An \emph{admissible trajectory}
	is a state trajectory \( \vecx \) for which
	the state variable constraints on \( \vecx(t) \) are obeyed
	over the interval \( [t_\il, t_\fl] \);
	let \( X \) denote the set of such admissible trajectories.
	\par
	Similarly, an \emph{admissible control}
	is a control curve \( \vecu \) for which
	the control constraints on \( \vecu(t) \) are obeyed
	over the interval \( [t_\il, t_\fl] \),
	and which causes the state \( \vecx(t) \) to follow
	an admissible trajectory \( \vecx \in X \);
	let \( U \) denote the set of such admissible controls.
\end{defn}

The optimal control problem can now be written more precisely:
Find an \emph{admissible control} \( \vecu\opt \)
which causes the system
\[
	\dot{\vecx}(t) =
		\func{\veca}{\vecx(t), \vecu(t), t}
\]
to follow an \emph{admissible trajectory} \( \vecx \)
that minimizes the performance measure
\[
	J = \func{h}{\vecx(t_\fl),t_\fl} +
		\intt{\func{g}{\vecx(t), \vecu(t), t} \dd t};
\]
\( \vecu\opt \) is called an \emph{optimal control} and
\( \vecx\opt \) an \emph{optimal trajectory}.

\presection
We now begin the actual topic of this report,
which is finding a closed-loop
\emph{optimal control law}, or \emph{optimal policy},
\[
	\vecu\opt(t) = \func{\mathbf{f}}{\vecx(t), t)}
\]
via \emph{dynamic programming}.

\section{The Principle of Optimality}
\begin{figure}[h]
	\centering
	\subfloat[][]{
		\label{fig:princeopt:optpath-a}
	\begin{tikzpicture}[>=stealth,thick]
		\draw[fill=black] (0.0,0.0)  circle (0.08) coordinate (a);
		\draw[fill=black] (1.0,1.0)  circle (0.08) coordinate (b);
		\draw[fill=black] (4.0,-0.4) circle (0.08) coordinate (e);

		\draw[with arrow] (a) node[below=1ex] {$a$} [out=70,in=220]
			to node[left=1ex] {$J_{ab}$} (b) node[above=1ex] {$b$};
		\draw[with arrow] (b) [out=-50, in=140] to
			node[below=1ex] {$J_{be}$} (e) node[right=1ex] {$e$};
	\end{tikzpicture}}
	\quad
	\subfloat[][]{
		\label{fig:princeopt:optpath-b}
	\begin{tikzpicture}[>=stealth,thick]
		\draw[fill=black] (0.0,0.0)  circle (0.08) coordinate (a);
		\draw[fill=black] (1.0,1.0)  circle (0.08) coordinate (b);
		\draw[fill=black] (2.8,1.1)  circle (0.08) coordinate (c);
		\draw[fill=black] (4.0,-0.4) circle (0.08) coordinate (e);

		\draw[with arrow] (a) node[below=1ex] {$a$} [out=70,in=220]
			to node[left=1ex] {$J_{ab}$} (b) node[above=1ex] {$b$};
		\draw[with arrow] (b) [out=-50, in=140] to
			node[below=1ex] {$J_{be}$} (e) node[right=1ex] {$e$};
		\draw[dashed] (b) [out=0,in=150] to (c) node[above=1ex] {$c$};
		\draw[dashed, with arrow] (c) [out=280,in=100] to
			node[above=1ex] {$J_{bce}$} (e);
	\end{tikzpicture}}
	\caption{\subref{fig:princeopt:optpath-a}
			Optimal path from $a$ to $e$.
			\subref{fig:princeopt:optpath-b}
			Two possible optimal paths from $b$ to $e$.}
	\label{fig:princeopt:optpath}
\end{figure}
See \Cref{fig:princeopt:optpath}.
The optimal path for a multistage decision process
is shown in \sfref{fig:princeopt:optpath-a}.

\section{Future Work}
The next Interim Report will focus on …

I am posting notes on my progress on my blog at
\url{http://optimalcontrol.wordpress.com/};
in-progress thesis work is in my publicly visible GitHub repository,
\url{http://github.com/jcsalomon/thesis}.

%\cleardoublepage
\printbibliography[heading=bibintoc]

\end{document}

